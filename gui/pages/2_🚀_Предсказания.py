"""
Predictions page
"""

import os
from time import sleep

import requests
import streamlit as st
from sklearn.metrics import mean_squared_error

from gui.utils import init_page, API_URL, read_dataset

init_page(title="–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è", desc="–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏")

trained_models = requests.get(f"{API_URL}/trained_models").json()["trained_models"]

if not trained_models:
    st.info("–ù–µ—Ç –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π", icon="‚ÑπÔ∏è")
    st.stop()

col1, col2 = st.columns(2)

model_id = col1.selectbox(
    label="–û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å",
    options=trained_models,
    help="–í—ã–±–µ—Ä–∏—Ç–µ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å",
)

dataset_name = col2.selectbox(
    label="–î–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è",
    options=list(os.listdir("datasets")),
    help="–í—ã–±–µ—Ä–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π",
)

X_test, y_test = read_dataset(dataset_name=dataset_name, data_type="test")

if st.button(
    label="–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è",
    help="–ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π",
    type="primary",
    use_container_width=True,
):
    with st.spinner("–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"):
        sleep(2)
        response = requests.post(
            f"{API_URL}/predict",
            json={
                "model_id": model_id,
                "features": X_test,
            },
        )

    if response.ok:
        predictions = response.json().get("predictions")
        st.info(
            f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {list(map(lambda x: round(x, 2), predictions))}", icon="‚ÑπÔ∏è"
        )
        st.info(f"MSE: {mean_squared_error(y_test, predictions):.2f}", icon="üìà")
    else:
        st.error(
            f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {response.json().get("detail", "unknown error")}",
            icon="üö®",
        )
